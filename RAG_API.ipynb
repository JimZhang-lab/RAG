{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.schema import AIMessage,SystemMessage,HumanMessage\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "\n",
    "# Initialize the chatbot\n",
    "chat = ChatOpenAI(\n",
    "    api_key = os.environ['ZHIPUAI_API_KEY'],\n",
    "    base_url = os.environ['ZHIPUAI_BASE_URL'],\n",
    "    model = os.environ['ZHIPUAI_MODEL_4airx'],\n",
    "    streaming=True, \n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = [\n",
    "    SystemMessage(content=\"You are a helpful assistant!\"),\n",
    "    HumanMessage(content=\"Knock knock.\"),\n",
    "    AIMessage(content=\"Who's there?\"),\n",
    "    HumanMessage(content=\"Java.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/testTTs/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java who?  \n",
      "Java is a language that never stops running, always compiling, and never quite done with you! (That's a play on the characteristics of the Java programming language, known for its continuous development and runtime environment.)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Java who?  \\nJava is a language that never stops running, always compiling, and never quite done with you! (That's a play on the characteristics of the Java programming language, known for its continuous development and runtime environment.)\", response_metadata={'finish_reason': 'stop', 'model_name': 'glm-4-airx'}, id='run-d62a5c5d-2275-4bc7-9720-f8d2be12fdcb-0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = chat(message)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理 LLM 存在的缺陷\n",
    "\n",
    "    1. 容易出现幻觉\n",
    "    2. 信息滞后\n",
    "    3. 专业领域深度知识缺乏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是的，我知道JimiAI模型。JimiAI是一种大型人工智能模型，它由中国的科技公司开发，旨在为各种商业和消费者应用提供智能支持。这个模型通过深度学习算法训练，能够理解和生成自然语言，执行复杂的任务，并提供决策支持。\n",
      "\n",
      "JimiAI模型通常具备以下特点：\n",
      "\n",
      "1. 强大的语言处理能力：JimiAI能够理解和生成自然语言，支持多轮对话，并且可以理解语境和情感。\n",
      "\n",
      "2. 广泛的知识库：它基于大规模数据集进行训练，拥有覆盖多个领域的丰富知识。\n",
      "\n",
      "3. 灵活性和通用性：JimiAI模型能够处理多样化的任务和问题，适应不同的应用场景。\n",
      "\n",
      "4. 持续学习和优化：这个模型能够通过不断的训练和迭代来提升性能，同时也能从用户反馈中进行学习。\n",
      "\n",
      "5. 定制化和集成能力：JimiAI可以根据特定需求进行定制，并且可以集成到其他系统或平台中，提供个性化的服务和解决方案。\n",
      "\n",
      "JimiAI模型可能被应用于客户服务、智能助手、教育辅导、数据分析等多个领域，帮助企业和组织提升效率，改善用户体验。随着人工智能技术的不断进步，JimiAI这样的模型也在不断地发展和完善中。"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='是的，我知道JimiAI模型。JimiAI是一种大型人工智能模型，它由中国的科技公司开发，旨在为各种商业和消费者应用提供智能支持。这个模型通过深度学习算法训练，能够理解和生成自然语言，执行复杂的任务，并提供决策支持。\\n\\nJimiAI模型通常具备以下特点：\\n\\n1. 强大的语言处理能力：JimiAI能够理解和生成自然语言，支持多轮对话，并且可以理解语境和情感。\\n\\n2. 广泛的知识库：它基于大规模数据集进行训练，拥有覆盖多个领域的丰富知识。\\n\\n3. 灵活性和通用性：JimiAI模型能够处理多样化的任务和问题，适应不同的应用场景。\\n\\n4. 持续学习和优化：这个模型能够通过不断的训练和迭代来提升性能，同时也能从用户反馈中进行学习。\\n\\n5. 定制化和集成能力：JimiAI可以根据特定需求进行定制，并且可以集成到其他系统或平台中，提供个性化的服务和解决方案。\\n\\nJimiAI模型可能被应用于客户服务、智能助手、教育辅导、数据分析等多个领域，帮助企业和组织提升效率，改善用户体验。随着人工智能技术的不断进步，JimiAI这样的模型也在不断地发展和完善中。', response_metadata={'finish_reason': 'stop', 'model_name': 'glm-4-airx'}, id='run-ad0881fd-9ac7-4d1c-80a3-d54b47ddb210-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = [\n",
    "    SystemMessage(content=\"你是一个专业知识助手\"),\n",
    "    HumanMessage(content=\"你是否知道 JimiAI 模型?\")\n",
    "]\n",
    "\n",
    "res = chat(message)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JimiAI 还在研发中,目前还没有什么功能,啥也不是\n",
      "JimiAI 是个一个法律大模型\n",
      "JimiAI 不会做任何事情\n"
     ]
    }
   ],
   "source": [
    "JimiAI_Information = [\n",
    "    \"JimiAI 还在研发中,目前还没有什么功能,啥也不是\",\n",
    "    \"JimiAI 是个一个法律大模型\",\n",
    "    \"JimiAI 不会做任何事情\"\n",
    "]\n",
    "\n",
    "source_knowledge = '\\n'.join(JimiAI_Information)\n",
    "print(source_knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"你知道什么是 JimiAI 吗？\"\n",
    "prompt_template = f\"\"\"基于一下内容回答问题:\n",
    "内容:{source_knowledge}\n",
    "Query:{query}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是的，我知道 JimiAI 是一个正在研发中的项目。根据提供的信息，JimiAI 被描述为一个法律大模型，但目前它还在开发阶段，还没有实现任何功能，也就是说它目前还不能执行任何任务或操作。"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='是的，我知道 JimiAI 是一个正在研发中的项目。根据提供的信息，JimiAI 被描述为一个法律大模型，但目前它还在开发阶段，还没有实现任何功能，也就是说它目前还不能执行任何任务或操作。', response_metadata={'finish_reason': 'stop', 'model_name': 'glm-4-airx'}, id='run-a13798dd-8634-4f2f-97c4-a33f3bb1a2e8-0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = HumanMessage(content=prompt_template)\n",
    "message.append(prompt)\n",
    "res = chat(message)\n",
    "# print(res.content)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建一个RAG对话\n",
    "1. 加载数据\n",
    "\n",
    "    以这篇论文为例：https://arxiv.org/abs/2408.01122<br/>\n",
    "    https://arxiv.org/pdf/2408.01122.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"./2408.01122v1.pdf\")\n",
    "\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': './2408.01122v1.pdf', 'page': 0}, page_content='CFBench: A Comprehensive Constraints-Following Benchmark for LLMs\\nTao Zhang1*♣, Yanjun Shen1*, Wenjing Luo1, Yan Zhang1, Hao Liang2, Tao Zhang1♢, Fan Yang1,\\nMingan Lin1, Yujing Qiao1, Weipeng Chen1, Bin Cui2, Wentao Zhang2†, Zenan Zhou1†\\n1Baichuan Inc.2Peking University\\n{♣zhangtao2, shenyanjun, zhouzenan }@baichuan-inc.com, {wentao.zhang }@pku.edu.cn\\nAbstract\\nThe adeptness of Large Language Models (LLMs) in compre-\\nhending and following natural language instructions is criti-\\ncal for their deployment in sophisticated real-world applica-\\ntions. Existing evaluations mainly focus on fragmented con-\\nstraints or narrow scenarios, but they overlook the compre-\\nhensiveness and authenticity of constraints from the user’s\\nperspective. To bridge this gap, we propose CFBench, a large-\\nscale Comprehensive Constraints Following Benchmark for\\nLLMs, featuring 1,000 curated samples that cover more than\\n200 real-life scenarios and over 50 NLP tasks. CFBench\\nmeticulously compiles constraints from real-world instruc-\\ntions and constructs an innovative systematic framework for\\nconstraint types, which includes 10 primary categories and\\nover 25 subcategories, and ensures each constraint is seam-\\nlessly integrated within the instructions. To make certain that\\nthe evaluation of LLM outputs aligns with user perceptions,\\nwe propose an advanced methodology that integrates multi-\\ndimensional assessment criteria with requirement prioritiza-\\ntion, covering various perspectives of constraints, instruc-\\ntions, and requirement fulfillment. Evaluating current leading\\nLLMs on CFBench reveals substantial room for improvement\\nin constraints following, and we further investigate influenc-\\ning factors and enhancement strategies. The data and code\\nare publicly available at https://github.com/PKU-Baichuan-\\nMLSystemLab/CFBench.\\nIntroduction\\nLarge Language Models (LLMs) have become the cor-\\nnerstone of numerous cutting-edge research tasks and are\\nwidely utilized in real-world scenarios (Brown et al. 2020;\\nChowdhery et al. 2023; Achiam et al. 2023; Touvron et al.\\n2023). In real-world scenarios, human instructions are in-\\nherently complex and accompanied by explicit constraints,\\nrequiring models to both understand intricate requirements\\nand strictly comply with these constraints (Yang et al. 2023;\\nZhong et al. 2021; Mishra et al. 2022; Wei et al. 2021; Sanh\\net al. 2022). The proficiency of LLMs in comprehending re-\\nquirements and adhering to natural language constraints is\\nessential, as it ensures tasks are executed precisely and re-\\nsolved perfectly according to user instructions.\\n*These authors contributed equally.\\n†Corresponding authors.\\nOverview of the Trump Shooting Incident, include the cause, process, impact, \\n aftermath, shooter information and Trump\\'s feedback. Organize the content using \\n numbered points and bold text. The cause should be in JSON format with event\\n keywords: time,  location, and  nature. Summarize the process in three sentences. \\n Discuss the impact from both international and domestic perspectives, keeping \\n the total content under 500 words. Finally,   summarize this event in a seven-word \\n quatrain.\\nOverview of the Trump Shooting Incident. 1.Cause \\\\n{\"time\":\"July 13, 2024\", \\n \"location\":\"Butler, Pennsylvania, USA\",\"nature\":\"assassination attempt\"} \\\\n \\n2.Process \\\\n-Trump was giving a speech at the rally when the shooting occurred.  \\n \\\\n-Secret Service agents quickly surrounded Trump and escorted him away. \\n3.Impact \\\\n-International: The incident shocked the world, raising concerns \\n about US political violence. \\\\n-Domestic: US political tensions and polarization \\n increased; Trump\\'s support may rise.\\\\n 4.Shooter Information: Details are not yet \\n released; the FBI is investigating.\\\\n 5.Seven-word quatrain : \\\\n-Former President \\n Trump was shot at a rally; the gunman was killed by the Secret Service, shocking \\n the world.\\n1.Content on Trump Shooting Incident\\n 2.Includes cause, process, impact ...\\n 3.Use numbered points and bold text')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 知识切片，将文档分割成均匀的块，每个块是一段原始文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter,CharacterTextSplitter\n",
    "'''\n",
    "* RecursiveCharacterTextSplitter 递归字符文本分割\n",
    "RecursiveCharacterTextSplitter 将按不同的字符递归地分割(按照这个优先级[\"\\n\\n\", \"\\n\", \" \", \"\"])，\n",
    "    这样就能尽量把所有和语义相关的内容尽可能长时间地保留在同一位置\n",
    "RecursiveCharacterTextSplitter需要关注的是4个参数：\n",
    "\n",
    "* separators - 分隔符字符串数组\n",
    "* chunk_size - 每个文档的字符数量限制\n",
    "* chunk_overlap - 两份文档重叠区域的长度\n",
    "* length_function - 长度计算函数\n",
    "'''\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "# text_splitter = CharacterTextSplitter(\n",
    "#     separator = '\\n\\n\\n',\n",
    "#     chunk_size=450,\n",
    "#     chunk_overlap=50,\n",
    "#     length_function=len,\n",
    "#     is_separator_regex=False,\n",
    "# )\n",
    "docs = text_splitter.split_documents(pages)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.pydantic_v1 import BaseModel, root_validator\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ZhipuAIEmbeddings(BaseModel, Embeddings):\n",
    "    \"\"\"`Zhipuai Embeddings` embedding models.\"\"\"\n",
    "\n",
    "    client: Any\n",
    "    \"\"\"`zhipuai.ZhipuAI\"\"\"\n",
    "\n",
    "    @root_validator()\n",
    "    def validate_environment(cls, values: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        实例化ZhipuAI为values[\"client\"]\n",
    "\n",
    "        Args:\n",
    "\n",
    "            values (Dict): 包含配置信息的字典，必须包含 client 的字段.\n",
    "        Returns:\n",
    "\n",
    "            values (Dict): 包含配置信息的字典。如果环境中有zhipuai库，则将返回实例化的ZhipuAI类；否则将报错 'ModuleNotFoundError: No module named 'zhipuai''.\n",
    "        \"\"\"\n",
    "        from zhipuai import ZhipuAI\n",
    "        values[\"client\"] = ZhipuAI()\n",
    "        return values\n",
    "    \n",
    "    def _embed(self, texts: str) -> List[float]:\n",
    "        embeddings = self.client.embeddings.create(\n",
    "            model=\"embedding-3\",\n",
    "            input=texts\n",
    "        )\n",
    "        return embeddings.data[0].embedding\n",
    "    \n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        生成输入文本列表的 embedding.\n",
    "        Args:\n",
    "            texts (List[str]): 要生成 embedding 的文本列表.\n",
    "\n",
    "        Returns:\n",
    "            List[List[float]]: 输入列表中每个文档的 embedding 列表。每个 embedding 都表示为一个浮点值列表。\n",
    "        \"\"\"\n",
    "        return [self._embed(text) for text in texts]\n",
    "    \n",
    "    \n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"\n",
    "        生成输入文本的 embedding.\n",
    "\n",
    "        Args:\n",
    "            texts (str): 要生成 embedding 的文本.\n",
    "\n",
    "        Return:\n",
    "            embeddings (List[float]): 输入文本的 embedding，一个浮点数值列表.\n",
    "        \"\"\"\n",
    "        resp = self.embed_documents([text])\n",
    "        return resp[0]\n",
    "\n",
    "\n",
    "\n",
    "    async def aembed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Asynchronous Embed search docs.\"\"\"\n",
    "        raise NotImplementedError(\"Please use `embed_documents`. Official does not support asynchronous requests\")\n",
    "\n",
    "    async def aembed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"Asynchronous Embed query text.\"\"\"\n",
    "        raise NotImplementedError(\"Please use `aembed_query`. Official does not support asynchronous requests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 利用 embedding 模型对每个文本片段进行向量化，并存到向量数据库中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "# from langchain.embeddings import QianfanEmbeddingsEndpoint\n",
    "# from langchain.embeddings.xinference import XinferenceEmbeddings\n",
    "# from langchain.embeddings.base import Embeddings\n",
    "import os\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# from zhipuembedding import ZhipuAIEmbeddings\n",
    "\n",
    "# bge_embeddings = embedding_functions.OpenAIEmbeddingFunction(\n",
    "#     api_base=os.environ[\"ZHIPUAI_API_URL\"],\n",
    "#     api_key=os.environ[\"ZHIPUAI_API_KEY\"],\n",
    "#     model_name= \"embedding-3\"\n",
    "# )\n",
    "embedding_model = ZhipuAIEmbeddings()\n",
    "\n",
    "# document_ebeddings = []\n",
    "# for text in docs:\n",
    "#     document_ebeddings.append(bge_embeddings(text))\n",
    "\n",
    "#测试，如有需要，删除数据库里的实验用cellection，清除之前的实验内容\n",
    "dbclient = chromadb.PersistentClient(path='./chorma_test_db')\n",
    "dbclient.delete_collection(name=\"zhipu_embedding\")\n",
    "\n",
    "# dbclient = chromadb.PersistentClient(path='./chorma_test_db')\n",
    "vector_store = Chroma.from_documents(documents=docs, embedding=embedding_model,persist_directory=\"./chorma_test_db\", collection_name=\"zhipu_embedding\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试，如有需要，删除数据库里的实验用cellection，清除之前的实验内容\n",
    "# dbclient = chromadb.PersistentClient(path='./chorma_test_db')\n",
    "# dbclient.delete_collection(name=\"zhipu_embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量库中存储的数量：185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/testTTs/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "vector_store.persist()\n",
    "print(f\"向量库中存储的数量：{vector_store._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How to construct high-quality evaluation data\"\n",
    "'''\n",
    "在向量存储中进行相似度搜索。\n",
    "query 参数是输入的查询字符串，即 \"What can CFBench do?\"。\n",
    "k=2 参数指定了返回结果的数量，这里设置为2，表示希望返回最相似的2个结果。\n",
    "'''\n",
    "result =  vector_store.similarity_search(query, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 1, 'source': './2408.01122v1.pdf'}, page_content='Q1: How to construct high-quality evaluation data?\\nMany studies focus on evaluating single constraint (Chen\\net al. 2022; Tang et al. 2023), lacking comprehensive anal-\\nysis across diverse constraints. He et al. (2024b) exam-\\nines LLM performance on complex real-world instructions\\nbut neglect constraint diversity and scenario coverage. Jiang\\net al. (2023) incrementally incorporate fine-grained con-'),\n",
       " Document(metadata={'page': 0, 'source': './2408.01122v1.pdf'}, page_content='realistic evaluation metrics reflect model capabilities and\\nguide iteration. Constraints-following evaluation faces anal-\\nogous challenges, particularly within complex real-world\\nscenarios, where data sources and contexts are diverse, and\\nwhere evaluation is both subjective and arduous. Fig. 1,\\nwhich addresses the aforementioned challenges, presents a\\nsample from CFBench illustrating the Trump assassinationarXiv:2408.01122v1  [cs.CL]  2 Aug 2024')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 原始 query 与检索得到的文本组合起来输入到语言模型，得到最终回答。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_prompt(query: str):\n",
    "    result = vector_store.similarity_search(query,k=10)\n",
    "    source_knowledge = \"\\n\".join([x.page_content for x in result])\n",
    "    augmented_prompt = f\"\"\"基于一下内容回答问题:\n",
    "    内容:{source_knowledge}\n",
    "    query:{query}\n",
    "    \"\"\"\n",
    "    return augmented_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基于一下内容回答问题:\n",
      "    内容:Q1: How to construct high-quality evaluation data?\n",
      "Many studies focus on evaluating single constraint (Chen\n",
      "et al. 2022; Tang et al. 2023), lacking comprehensive anal-\n",
      "ysis across diverse constraints. He et al. (2024b) exam-\n",
      "ines LLM performance on complex real-world instructions\n",
      "but neglect constraint diversity and scenario coverage. Jiang\n",
      "et al. (2023) incrementally incorporate fine-grained con-\n",
      "realistic evaluation metrics reflect model capabilities and\n",
      "guide iteration. Constraints-following evaluation faces anal-\n",
      "ogous challenges, particularly within complex real-world\n",
      "scenarios, where data sources and contexts are diverse, and\n",
      "where evaluation is both subjective and arduous. Fig. 1,\n",
      "which addresses the aforementioned challenges, presents a\n",
      "sample from CFBench illustrating the Trump assassinationarXiv:2408.01122v1  [cs.CL]  2 Aug 2024\n",
      "limited scenarios, and misaligned evaluation methods with\n",
      "user perspectives.\n",
      "CFBench\n",
      "As depicted in Fig. 2, the CFBench construction pipeline in-\n",
      "cludes several key components. First, we collect and system-\n",
      "atize constraint expressions from real-world scenarios and\n",
      "various NLP tasks. Using this system, we create high-quality\n",
      "evaluation data by combining instructions from these sce-\n",
      "narios with advanced LLMs and manual curation. We then\n",
      "data points: 500 from real-world scenarios and 500 from dif-\n",
      "ferent NLP tasks. Specifically, we implemented the follow-\n",
      "ing steps to enhance data quality for manual annotations.\n",
      "Annotator Training We sourced annotation contractors\n",
      "from the public and selected 21 candidates for training by\n",
      "seasoned data scientists. After a one-week training program,\n",
      "the annotators engaged in multiple rounds of trial annota-\n",
      "structions are revised, and LLMs generate responses with\n",
      "refined evaluation criteria, repeating this process until satis-\n",
      "factory results are achieved. Ultimately, comprehensive sup-\n",
      "port is formulated for each sample, detailing high-quality\n",
      "instructions, the ideal answer, specific assessment criteria,\n",
      "constraint types, and priority levels, totaling 1000 entries.\n",
      "Dataset Statistics\n",
      "Overall Statistics Tab. 1 provides a statistical overview of\n",
      "dataset, it was systematically divided for processing. Fol-\n",
      "lowing a phased improvement approach, the initial batch\n",
      "sizes were set at 50, 100, and 200, gradually increasing to\n",
      "400 for later batches. After the annotation process, 50%\n",
      "of the dataset was randomly selected for contractor review,\n",
      "while 20% of the dataset was examined by experts.\n",
      "Data Split We used a voting mechanism involving experts\n",
      "each sample, paying particular attention to nuanced combi-\n",
      "nations, ensuring each constraint is credibly and coherentlyembedded. Our advanced evaluation methodology incorpo-\n",
      "rates multi-dimensional assessment criteria, which prioritiz-\n",
      "ing requirements to align LLM outputs with user needs, en-\n",
      "hance interpretability, and facilitate iterative development.\n",
      "Finally, extensive experiments and exploratory discussions\n",
      "of data. This method involved leveraging advanced LLMs to\n",
      "augment original instructions with additional constraints and\n",
      "generate corresponding responses. These responses were\n",
      "meticulously reviewed for constraint validity, followed by\n",
      "the creation of detailed checklists for each example. Mul-\n",
      "tiple experts participated in this iterative process, continu-\n",
      "ously refining the outputs by addressing issues encountered\n",
      "Details are in Appendix Tab. 8.\n",
      "Dataset Construction\n",
      "To guarantee data quality in terms of authority and thorough\n",
      "coverage, we utilize a collaborative iterative methodology\n",
      "dates. Second, we implemented a stringent manual annota-\n",
      "tion process, including annotator training, cross-validation,\n",
      "batch validation, expert team involvement, and iterative re-\n",
      "finement of instruction constraints and response quality. We\n",
      "also ensured the objectivity, evaluability, and prioritization\n",
      "of checkpoints. Additionally, we balanced the data for con-\n",
      "straint types, scenarios, and NLP task distribution. Detailed\n",
      "    query:How to construct high-quality evaluation data\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(augment_prompt(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "构建高质量评估数据的方法包括以下几个步骤：\n",
      "\n",
      "1. **数据来源的多样性和现实性**：从现实世界的场景和不同的自然语言处理任务中收集数据点。例如，文中提到的CFBench包含了500个来自现实世界的场景和500个来自不同NLP任务的数据点。\n",
      "\n",
      "2. **约束系统的构建**：从现实世界场景和各种NLP任务中收集和系统化约束表达式，形成约束系统。\n",
      "\n",
      "3. **注释者培训**：从公众中招募注释者，并由经验丰富的数据科学家进行培训。培训后，注释者进行多轮试注释，以确保他们能够准确理解并执行注释任务。\n",
      "\n",
      "4. **分阶段的数据处理**：初始批次的数据量较小，例如50、100和200，然后逐渐增加到400。这种分阶段的改进方法有助于逐步提高数据质量。\n",
      "\n",
      "5. **数据分割和审查**：在注释过程结束后，随机选取50%的数据由承包商进行审查，20%的数据由专家进行检查。\n",
      "\n",
      "6. **质量评估**：采用多种方法验证随机选取的100个样本的质量。例如，邀请三位专家独立评估每个样本的指令、响应和标准的质量，并计算平均质量率。\n",
      "\n",
      "7. **迭代改进**：根据专家的反馈，对指令进行修订，并让大型语言模型（LLMs）根据精化的评估标准生成响应，重复这个过程直到达到满意的结果。\n",
      "\n",
      "8. **综合支持**：为每个样本制定全面的支持方案，包括高质量的指令、理想答案、具体的评估标准、约束类型和优先级。\n",
      "\n",
      "9. **监督微调（SFT）**：通过监督微调来提高模型的约束遵循能力，文中提到这种方法可以显著提高模型的有效性。\n",
      "\n",
      "10. **考虑模型规模和评估指标**：模型的大小和评估指标的选择对于反映模型能力和指导迭代至关重要。\n",
      "\n",
      "通过这些步骤，可以构建出一个既全面又高质量的评估数据集，以用于评估和改进大型语言模型在遵循约束方面的能力。构建高质量评估数据的方法包括以下几个步骤：\n",
      "\n",
      "1. **数据来源的多样性和现实性**：从现实世界的场景和不同的自然语言处理任务中收集数据点。例如，文中提到的CFBench包含了500个来自现实世界的场景和500个来自不同NLP任务的数据点。\n",
      "\n",
      "2. **约束系统的构建**：从现实世界场景和各种NLP任务中收集和系统化约束表达式，形成约束系统。\n",
      "\n",
      "3. **注释者培训**：从公众中招募注释者，并由经验丰富的数据科学家进行培训。培训后，注释者进行多轮试注释，以确保他们能够准确理解并执行注释任务。\n",
      "\n",
      "4. **分阶段的数据处理**：初始批次的数据量较小，例如50、100和200，然后逐渐增加到400。这种分阶段的改进方法有助于逐步提高数据质量。\n",
      "\n",
      "5. **数据分割和审查**：在注释过程结束后，随机选取50%的数据由承包商进行审查，20%的数据由专家进行检查。\n",
      "\n",
      "6. **质量评估**：采用多种方法验证随机选取的100个样本的质量。例如，邀请三位专家独立评估每个样本的指令、响应和标准的质量，并计算平均质量率。\n",
      "\n",
      "7. **迭代改进**：根据专家的反馈，对指令进行修订，并让大型语言模型（LLMs）根据精化的评估标准生成响应，重复这个过程直到达到满意的结果。\n",
      "\n",
      "8. **综合支持**：为每个样本制定全面的支持方案，包括高质量的指令、理想答案、具体的评估标准、约束类型和优先级。\n",
      "\n",
      "9. **监督微调（SFT）**：通过监督微调来提高模型的约束遵循能力，文中提到这种方法可以显著提高模型的有效性。\n",
      "\n",
      "10. **考虑模型规模和评估指标**：模型的大小和评估指标的选择对于反映模型能力和指导迭代至关重要。\n",
      "\n",
      "通过这些步骤，可以构建出一个既全面又高质量的评估数据集，以用于评估和改进大型语言模型在遵循约束方面的能力。\n"
     ]
    }
   ],
   "source": [
    "# 创建 prompt\n",
    "prompt = HumanMessage(\n",
    "    content = augment_prompt(query+\"请用中文回答。\")\n",
    ")\n",
    "message.append(prompt)\n",
    "res = chat(message)\n",
    "\n",
    "print(res.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testTTs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
